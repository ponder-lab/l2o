import tensorflow as tf
import numpy as np
import collections

from tensorflow.keras.utils import Progbar

from .utils import reset_optimizer


_MetaIteration = collections.namedtuple(
    "MetaIteration", [
        "problem", "optimizer",
        "unroll_len", "unroll_weights",
        "teachers", "strategy", "p_teacher"
    ])


class MetaIteration(_MetaIteration):
    """Meta Iteration args storage class

    Attributes
    ----------
    problem : problem.Problem
        Problem to train on. Presence of ``.get_dataset()`` or
        ``.get_internal()`` indicates full or minibatch.
    optimizer : tf.keras.optimizers.Optimizer
        Optimizer to use for meta optimization
    unroll_len : Callable -> int
        Callable that returns unroll size.
    unroll_weights : Callable(int) -> tf.Tensor
        Callable that generates unroll weights from an unroll size.
    teacher : tf.keras.optimizers.Optimizer
        Optimizer to imitate; trains meta-loss if not passed.
    """
    pass


def weights_sum(n):
    return tf.ones([n])


def weights_mean(n):
    return tf.ones([n]) / tf.cast(n, tf.float32)


class TrainingMixin:

    def _make_cf(
            self, meta, weights, data, unroll, params=None, states=None,
            global_state=None, is_batched=False):
        """Helper function to make a concrete function for the given params.

        A concrete function is a single graph generated by AutoGraph; see
        ``https://www.tensorflow.org/guide/concrete_function``.

        In general, the rules are (as of 2.3.0-rc1):
          - Nested structures (lists, dicts of Tensors) must maintain the same
            internal values and dimensions
          - Python objects are 'bound' and must be constant (i.e. id())
          - BUG: non-primitive python objects can only be passed during
            .get_concrete_function() and must not be passed again when called.
            This is because non-primitive objects are interpreted as
            ``UnknownArgument`` by tensorflow.
        """

        kwargs = dict(
            params=params, states=states, global_state=global_state,
            unroll=unroll, problem=meta.problem, is_batched=is_batched)

        # P(meta learning) > 0
        if meta.p_teacher < 1:
            cf_meta = self.meta_loss.get_concrete_function(
                weights, data, noise_stddev=meta.problem.noise_stddev,
                **kwargs)
        else:
            cf_meta = None
        # Teachers are not empty and P(imitation learning) > 0
        if len(meta.teachers) > 0 and meta.p_teacher > 0:
            cf_imitation = self.imitation_loss.get_concrete_function(
                weights, data, teachers=meta.teachers,
                strategy=meta.strategy, **kwargs)
        else:
            cf_imitation = None

        return cf_meta, cf_imitation

    def _meta_step(
            self, p_teacher, optimizer, concrete_loss, weights, data,
            params=None, states=None, global_state=None):
        """Helper function to run for a single step."""

        cf_meta, cf_imitation = concrete_loss
        # Only imitation learning or only meta learning
        if cf_meta is None:
            _loss = cf_imitation
        elif cf_imitation is None:
            _loss = cf_meta
        # Randomly select meta or imitation learning
        else:
            concrete_loss = np.random.choice(
                [cf_meta, cf_imitation], p=[1. - p_teacher, p_teacher])

        # Specify trainable_variables specifically for efficiency
        with tf.GradientTape(watch_accessed_variables=False) as tape:
            tape.watch(self.trainable_variables)
            # Other arugments of ``concrete_loss`` are bound and do not
            # need to be passed.
            loss, params, states, global_state = _loss(
                weights, data,
                params=params, states=states, global_state=global_state)
        # Standard apply_gradient paradigam
        # Used instead of ``optimizer.minimize`` to expose the current loss
        grads = tape.gradient(loss, self.trainable_variables)
        optimizer.apply_gradients(zip(grads, self.trainable_variables))

        return loss, params, states, global_state

    def _train_full(self, meta, repeat=1):
        """Full batch training.

        Parameters
        ----------
        meta : MetaIteration
            Current metaiteration parameters. See docstring.

        Keyword Args
        ------------
        repeat : int
            Number of times to repeat. reset() is used for computational
            efficiency (the loss graph is not rebuilt between repeats).
        """

        pbar = Progbar(repeat, unit_name='step')
        concrete_loss = None

        for _ in range(repeat):

            unroll = meta.unroll_len()
            weights = meta.unroll_weights(unroll)
            data = meta.problem.get_internal()

            if meta.teachers is not None:
                # Reset only required when ``persistent=True``
                meta.problem.reset(internal=data)
                # Teacher state (i.e. momentum) needs to be reset
                for t in meta.teachers:
                    reset_optimizer(t)

            # Only create concrete loss on first iteration
            if concrete_loss is None:
                concrete_loss = self._make_cf(meta, weights, data, unroll)

            # Ignore all param & state arguments
            loss, _, _, _ = self._meta_step(
                meta.p_teacher, meta.optimizer, concrete_loss, weights, data)

            pbar.add(1, values=[("loss", loss)])

    def _train_batch(self, meta, epochs=1, persistent=False):
        """Minibatch training.

        Parameters
        ----------
        meta : MetaIteration
            Current metaiteration parameters. See docstring.

        Keyword Args
        ------------
        epochs : int
            Number of epochs to run for.
        persistent : bool
            If True, batch training keeps a persistent optimizer and optimizee
            state across iteration trajectories. If False, the optimizer state
            is reset after every iteration.
        """
        concrete_loss = None
        if persistent:
            params, states, global_state = self._get_state(
                meta.problem, params=None, states=None, global_state=None)
        else:
            params = meta.problem.get_parameters()
            states = None
            global_state = None

        for i in range(epochs):

            unroll = meta.unroll_len()
            weights = meta.unroll_weights(unroll)
            dataset = meta.problem.get_dataset(unroll)

            print("Epoch {}".format(i + 1))
            pbar = Progbar(meta.problem.size(unroll), unit_name='step')

            for batch in dataset:

                if meta.teachers is not None:
                    # Sync with student
                    meta.problem.reset(values=params)
                    # Teacher state (i.e. momentum) needs to be reset
                    if not persistent:
                        for t in meta.teachers:
                            reset_optimizer(t)

                # Data dimensions are ``[unroll, batch] + [data]``
                batch_stacked = [
                    tf.stack(tf.split(dim, num_or_size_splits=unroll))
                    for dim in batch]

                # Only create concrete loss on first iteration
                if concrete_loss is None:
                    concrete_loss = self._make_cf(
                        meta, weights, batch_stacked, unroll, params=params,
                        states=states, global_state=global_state,
                        is_batched=True)

                # The actual step
                loss, params, states, global_state = self._meta_step(
                    meta.p_teacher, meta.optimizer, concrete_loss, weights,
                    batch_stacked,
                    params=params, states=states, global_state=global_state)

                # not persistent -> discard state, global_state
                if not persistent:
                    states = None
                    global_state = None

                pbar.add(1, values=[("loss", loss)])

    def train(
            self, problems, optimizer,
            unroll_len=lambda: 20, unroll_weights=weights_mean,
            teachers=[], strategy=tf.math.reduce_mean, p_teacher=0,
            epochs=1, repeat=1, persistent=False):
        """Run meta-training.

        Parameters
        ----------
        problems : problem.ProblemSpec[]
            List of problem specifications to build and run
        optimizer : tf.keras.optimizers.Optimizer
            Optimizer to use for meta optimization

        Keyword Args
        ------------
        unroll_len : Callable -> int
            Unroll size or callable that returns unroll size.
        unroll_weights : Callable(int) -> tf.Tensor
            Callable that generates unroll weights from an unroll size.
        teachers : tf.keras.optimizers.Optimizer[]
            If passed, runs imitation learning instead against ``teacher``.
        strategy : Callable (float[] -> float)
            Imitation learning multi-teacher loss strategy. Suggested:
              - ``tf.math.reduce_mean``: classic multi-teacher mean loss.
              - ``tf.math.reduce_max``: minimax loss.
            Can also implement a custom multi-teacher strategy.
        p_teacher : float
            Probability of choosing imitation learning. Cannot be >0 if
            teachers is empty.
        epochs : int
            Number of epochs to run if batched
        repeat : int
            Number of repetitions to run using the same graph if full batched.
        persistent : bool
            If True, batch training keeps a persistent optimizer and optimizee
            state across iteration trajectories. If False, the optimizer state
            is reset after every iteration.
        """

        for itr, spec in enumerate(problems):
            spec.print(itr)
            problem = spec.build(persistent=len(teachers))

            meta = MetaIteration(
                problem, optimizer, unroll_len, unroll_weights, teachers,
                strategy, p_teacher)

            if hasattr(problem, "get_dataset"):
                self._train_batch(meta, epochs=epochs, persistent=persistent)
            elif hasattr(problem, "get_internal"):
                self._train_full(meta, repeat=repeat)
            else:
                raise TypeError(
                    "Problem must be able to either get_dataset() or"
                    + "get_internal().")
