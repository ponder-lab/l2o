import tensorflow as tf
import numpy as np
import collections

from tensorflow.keras.utils import Progbar

from .utils import reset_optimizer


MetaIteration = collections.namedtuple(
    "MetaIteration", [
        "problem", "optimizer",
        "unroll_len", "unroll_weights",
        "teachers", "imitation_optimizer", "strategy", "p_teacher",
        "validation"
    ])


builtin_weights = {
    "sum": lambda n: tf.ones([n]),
    "mean": lambda n: tf.ones([n]) / tf.cast(n, tf.float32)
}


class TrainingMixin:

    def _regen_teacher_vars(self, meta):
        """Helper function to force teacher optimizers to generate hidden
        state variables.
        As of 2.3.0-rc2, I believe f.keras.optimizers.Optimizer has a
        compatibility issue with get_concrete_function. Using
        get_concrete_function triggers two traces, and sometimes causes issues
        on the second retrace with the optimizer trying to create variables.
        Therefore, this method forcibly generates hidden variables outside of
        the @tf.function loss functions to avoid this bug.
        """
        if len(meta.teachers) > 0:
            pairs = zip(meta.teachers, meta.problem.trainable_variables)
            for teacher, var_set in pairs:
                teacher._create_all_weights(var_set)

    def _make_cf(self, meta, data, unroll_state, is_batched=False):
        """Helper function to make a concrete function for the given params.

        A concrete function is a single graph generated by AutoGraph; see
        ``https://www.tensorflow.org/guide/concrete_function``.

        In general, the rules are (as of 2.3.0-rc1):
          - Nested structures (lists, dicts of Tensors) must maintain the same
            internal values and dimensions
          - Python objects are 'bound' and must be constant (i.e. id())
          - BUG: non-primitive python objects can only be passed during
            .get_concrete_function() and must not be passed again when called.
            This is because non-primitive objects are interpreted as
            ``UnknownArgument`` by tensorflow.
        """

        kwargs = dict(
            unroll_state=unroll_state,
            unroll=meta.unroll, problem=meta.problem, is_batched=is_batched)

        # P(meta learning) > 0
        if meta.p_teacher < 1:
            kwargs["noise_stddev"] = meta.problem.noise_stddev
            if meta.validation:
                cf_meta = self.meta_loss.get_concrete_function(
                    meta.weights, data, **kwargs)
            else:
                cf_meta = self.meta_step.get_concrete_function(
                    meta.optimizer, meta.weights, data, **kwargs)
        else:
            cf_meta = None
        # Teachers are not empty and P(imitation learning) > 0
        if len(meta.teachers) > 0 and meta.p_teacher > 0:
            kwargs["teachers"] = meta.teachers
            kwargs["strategy"] = meta.strategy
            if meta.validation:
                cf_imitation = self.imitation_loss.get_concrete_function(
                    meta.weights, data, **kwargs)
            else:
                cf_imitation = self.imitation_step.get_concrete_function(
                    meta.optimizer, meta.weights, data, **kwargs)
        else:
            cf_imitation = None

        return cf_meta, cf_imitation

    def _meta_step(self, meta, concrete_step, data, unroll_state):
        """Helper function to run for a single step."""

        cf_meta, cf_imitation = concrete_step
        # Only imitation learning or only meta learning
        if cf_meta is None:
            is_imitation = True
        elif cf_imitation is None:
            is_imitation = False
        # Randomly select meta or imitation learning
        else:
            is_imitation = np.random.uniform(0, 1) > 0.5

        concrete_function = cf_imitation if is_imitation else cf_meta

        if meta.validation:
            return concrete_function(meta.weights, data, unroll_state)
        else:
            opt = meta.imitation_optimizer if is_imitation else meta.optimizer
            return concrete_function(opt, meta.weights, data, unroll_state)

    def _train_full(self, meta, repeat=1):
        """Full batch training.

        Parameters
        ----------
        meta : MetaIteration
            Current metaiteration parameters. See ``train`` docstring.

        Keyword Args
        ------------
        repeat : int
            Number of times to repeat.

        Returns
        -------
        float
            Mean training loss for this meta-iteration
        """
        # No states are persistent
        unroll_state = self._make_unroll_state(
            meta.problem, params=None, states=None, global_state=None)
        concrete_step = None

        pbar = Progbar(repeat, unit_name='step')

        losses = np.zeros(repeat, dtype=np.float32)
        for i in range(repeat):

            data = meta.problem.get_internal()

            self.reset()
            meta.problem.reset(internal=data)
            # State (i.e. momentum) needs to be reset
            for t in meta.teachers:
                reset_optimizer(t)

            # Only create concrete loss on first iteration
            if concrete_step is None:
                concrete_step = self._make_cf(meta, data, unroll_state)

            loss, unroll_state = self._meta_step(
                meta, concrete_step, data, unroll_state)

            pbar.add(1, values=[("loss", loss)])
            losses[i] = loss.numpy()

        return np.mean(losses)

    def _train_batch(self, meta, epochs=1, depth=1, persistent=False):
        """Minibatch training.

        Parameters
        ----------
        meta : MetaIteration
            Current metaiteration parameters. See ``train`` docstring.

        Keyword Args
        ------------
        epochs : int
            Number of epochs to run for.
        persistent : bool
            Keeps a persistent optimizer?
        depth : int
            Optimization depth.

        Returns
        -------
        float
            Mean training loss for this meta-iteration
        """
        unroll_state = self._make_unroll_state(
            meta.problem,
            params=True, states=persistent, global_state=persistent)
        concrete_step = None

        size = meta.problem.size(meta.unroll_len)
        pbar = Progbar(size * epochs, unit_name='step')

        # See docstring for why this is necessary
        self._regen_teacher_vars(meta)

        losses = np.zeros(epochs, dtype=np.float32)
        for i in range(epochs):

            dataset = meta.problem.get_dataset(meta.unroll)
            epoch_losses = np.zeros(size, dtype=np.float32)

            for j, batch in enumerate(dataset):
                # State (i.e. momentum) needs to be reset
                if not persistent:
                    self.reset()
                    for t in meta.teachers:
                        reset_optimizer(t)
                # Sync with student
                meta.problem.reset(values=unroll_state.params)

                # Data dimensions are ``[unroll, batch] + [data]``
                batch_stacked = [
                    tf.stack(tf.split(dim, num_or_size_splits=meta.unroll))
                    for dim in batch]

                # Only create concrete loss on first iteration
                if concrete_step is None:
                    concrete_step = self._make_cf(
                        meta, batch_stacked, unroll_state, is_batched=True)
                # The actual step
                loss, unroll_state = self._meta_step(
                    meta, concrete_step, batch_stacked, unroll_state)

                # Every ``depth`` iterations, reset parameters
                if depth > 0 and (i + 1) % depth == 0:
                    unroll_state.params = meta.problem.get_parameters()

                pbar.add(1, values=[("loss", loss)])
                epoch_losses[j] = loss.numpy()

            losses[i] = np.mean(epoch_losses)

        return np.mean(losses)

    def train(
            self, problems, optimizer,
            unroll_len=lambda: 20, unroll_weights="sum",
            teachers=[], imitation_optimizer=None,
            strategy="mean", p_teacher=0,
            epochs=1, depth=0, repeat=1, persistent=False, validation=False):
        """Run meta-training.

        Parameters
        ----------
        problems : problem.ProblemSpec[]
            List of problem specifications to build and run
        optimizer : tf.keras.optimizers.Optimizer
            Optimizer to use for meta optimization

        Keyword Args
        ------------
        unroll_len : Callable -> int
            Unroll size or callable that returns unroll size.
        unroll_weights : str or Callable(int) -> tf.Tensor
            Callable that generates unroll weights from an unroll size.
        teachers : tf.keras.optimizers.Optimizer[]
            If passed, runs imitation learning instead against ``teacher``.
        imitation_optimizer : tf.keras.optimizers.Optimizer
            Separate optimizer to use on imitation loss updates if present.
            This may benefit optimization by keeping separate optimizer
            states for imitation and meta learning, as those losses may have
            vastly different gradient magnitudes.
        strategy : str or Callable (float[] -> float)
            Imitation learning multi-teacher loss strategy. Suggested:
              - "mean" or ``tf.math.reduce_mean``: classic mean loss.
              - "max" or ``tf.math.reduce_max``: minimax loss.
            Can also implement a custom multi-teacher strategy.
        p_teacher : float
            Probability of choosing imitation learning. Cannot be >0 if
            teachers is empty.
        epochs : int
            Number of epochs to run if batched
        depth : int
            Optimization depth, in meta-iterations, before the parameters
            should be reinitialized. If 0, is treated as infinity (no resets).
            A larger optimization depth allows more opportunities to train
            on more refined optimization. Only operates when not in persistent
            mode.
        repeat : int
            Number of repetitions to run using the same graph if full batched.
        persistent : bool
            If True, batch training keeps a persistent optimizer and optimizee
            state across iteration trajectories. If False, the optimizer state
            is reset after every iteration.
        validation : bool
            If True, runs in validation mode (does not perform any parameter
            updates)

        Returns
        -------
        float[]
            Logged loss and training modes for all problems; arranged in the
            same order as ``problems``.
        """
        # No imitation optimizer -> use same optimizer for both
        if imitation_optimizer is None:
            imitation_optimizer = optimizer

        results = []

        # Deserialize
        if type(unroll_weights) == str:
            try:
                unroll_weights = builtin_weights[unroll_weights]
            except KeyError:
                raise ValueError(
                    "Invalid unroll_weights: {}".format(unroll_weights))
        if type(strategy) == str:
            try:
                strategy = getattr(tf.math, "reduce_" + strategy)
            except AttributeError:
                raise ValueError(
                    "Invalid reduce strategy: {}".format("reduce_" + strategy))
        # tf.keras.optimizers.get will pass through if already a optimizer
        teachers = [tf.keras.optimizers.get(t) for t in teachers]

        for itr, spec in enumerate(problems):
            spec.print(itr)
            problem = spec.build(persistent=len(teachers))
            unroll = unroll_len()

            meta = MetaIteration(
                problem, optimizer, unroll, unroll_weights(unroll), teachers,
                imitation_optimizer, strategy, p_teacher, validation)

            if hasattr(problem, "get_dataset"):
                results.append(
                    self._train_batch(
                        meta, epochs=epochs, depth=depth,
                        persistent=persistent))
            elif hasattr(problem, "get_internal"):
                results.append(
                    self._train_full(meta, repeat=repeat))
            else:
                raise TypeError(
                    "Problem must be able to either get_dataset() or"
                    + "get_internal().")

        return results
